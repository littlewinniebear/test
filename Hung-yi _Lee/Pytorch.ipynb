{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will be intoducing PyTorch, \"an open source deep learning platform that provides a seamless path from research prototyping to production deployment\".\n",
    "\n",
    "This notebook is by no means comprehensive. If you have any questions the documentation and Google are your friends.\n",
    "\n",
    "Goal takeaways:\n",
    "\n",
    "Automatic differentiation is a powerful tool\n",
    "PyTorch implements common functions used in deep learning\n",
    "Data Processing with PyTorch DataSet\n",
    "Mixed Presision Training in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "Tensors and relation to numpy\n",
    "By this point, we have worked with numpy quite a bit. PyTorch's basic building block, the tensor is similar to numpy's ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_numpy, x_torch\n",
      "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
      "\n",
      "to and from numpy and pytorch\n",
      "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
      "\n",
      "x+y\n",
      "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
      "\n",
      "norm\n",
      "0.37416573867739417 tensor(0.3742)\n",
      "\n",
      "mean along the 0th dimension\n",
      "[2. 3.] tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# we create tensors in a similar way to numpy nd arrays\n",
    "x_numpy = np.array([0.1, 0.2, 0.3])\n",
    "x_torch = torch.tensor([0.1, 0.2, 0.3])\n",
    "print('x_numpy, x_torch')\n",
    "print(x_numpy, x_torch)\n",
    "print()\n",
    "\n",
    "# to and from numpy, pytorch\n",
    "print('to and from numpy and pytorch')\n",
    "print(torch.from_numpy(x_numpy), x_torch.numpy())\n",
    "print()\n",
    "\n",
    "# we can do basic operations like +-*/\n",
    "y_numpy = np.array([3,4,5.])\n",
    "y_torch = torch.tensor([3,4,5.])\n",
    "print(\"x+y\")\n",
    "print(x_numpy + y_numpy, x_torch + y_torch)\n",
    "print()\n",
    "\n",
    "# many functions that are in numpy are also in pytorch\n",
    "print(\"norm\")\n",
    "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\n",
    "print()\n",
    "\n",
    "# to apply an operation along a dimension,\n",
    "# we use the dim keyword argument instead of axis\n",
    "print(\"mean along the 0th dimension\")\n",
    "x_numpy = np.array([[1,2],[3,4.]])\n",
    "x_torch = torch.tensor([[1,2],[3,4.]])\n",
    "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 28, 28])\n",
      "torch.Size([10000, 3, 784])\n",
      "torch.Size([10000, 3, 784])\n"
     ]
    }
   ],
   "source": [
    "N, C, W, H = 10000, 3, 28, 28\n",
    "X = torch.randn((N, C, W, H))\n",
    "\n",
    "print(X.shape)\n",
    "print(X.view(N, C, 784).shape)\n",
    "print(X.view(-1, C, 784).shape) # automatically choose the 0th dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c tensor(3., grad_fn=<AddBackward0>)\n",
      "d tensor(2., grad_fn=<AddBackward0>)\n",
      "e tensor(6., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True) # we set requires_grad=True to let PyTorch know to keep the graph\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print('c', c)\n",
    "print('d', d)\n",
    "print('e', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
      "PyTorch's f'(x): tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (x-2)**2\n",
    "\n",
    "def fp(x):\n",
    "    return 2*(x-2)\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "y = f(x)\n",
    "y.backward()\n",
    "\n",
    "print('Analytical f\\'(x):', fp(x))\n",
    "print('PyTorch\\'s f\\'(x):', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It can also find gradients of functions.\n",
    "\n",
    "Let w=[w1,w2]T\n",
    "Consider g(w)=2w1w2+w2cos(w1)\n",
    "Q: Compute ∇wg(w) and verify ∇wg([π,1])=[2,π−1]T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 5.2832])\n",
      "tensor([2.0000, 5.2832])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(w):\n",
    "    return 2*w[0]*w[1]+w[1]*torch.cos(w[0])\n",
    "def fp(w):\n",
    "    return torch.tensor([2*w[1]-w[1]*torch.sin(w[0]),2*w[0]+torch.cos(w[0])])\n",
    "x = torch.tensor([np.pi,1],requires_grad=True)\n",
    "y = f(x)\n",
    "y.backward()\n",
    "print(fp(x))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
      "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
      "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
      "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
      "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
      "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
      "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
      "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
      "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
      "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
      "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
      "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
      "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
      "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
      "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (x-2)**2\n",
    "\n",
    "def fp(x):\n",
    "    return 2*(x-2)\n",
    "x = torch.tensor([5.],requires_grad=True)\n",
    "step_size = 0.25\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
    "#     x.data -= step_size*x.data\n",
    "    x.data = x.data - step_size * x.grad\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape torch.Size([50, 2])\n",
      "y shape torch.Size([50, 1])\n",
      "w shape torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "n = 50\n",
    "X = torch.randn(n,d)\n",
    "true_w = torch.tensor([[-1.0], [2.0]])\n",
    "y = X @ true_w + torch.randn(n,1) * 0.1\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "print('w shape', true_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∇wLRSS(w;X)=∇w1n||y−Xw||22=−2nXT(y−Xw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "n = 50\n",
    "X = torch.randn(n,d)\n",
    "true_w = torch.tensor([[-1.0], [2.0]])\n",
    "y = X @ true_w + torch.randn(n,1) * 0.1\n",
    "def model(w,x):\n",
    "    return x @ w\n",
    "def RSS(y, y_hat):\n",
    "    return torch.norm(y-y_hat)**2/n\n",
    "def grad_rss(X, y ,y_hat):\n",
    "    return -2*x.t() @ (y-x @ W)/n\n",
    "w = torch.tensor([[1.],[0]],requires_grad=True)\n",
    "y_hat = model(w,X)\n",
    "loss = RSS(y, y_hat)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient [ 5.6441026 -4.8636155]\n",
      "PyTorch's gradient [ 5.6441035 -4.8636155]\n"
     ]
    }
   ],
   "source": [
    "def model(X, w):\n",
    "    return X @ w\n",
    "\n",
    "# the residual sum of squares loss function\n",
    "def rss(y, y_hat):\n",
    "    return torch.norm(y - y_hat)**2 / n\n",
    "\n",
    "# analytical expression for the gradient\n",
    "def grad_rss(X, y, w):\n",
    "    return -2*X.t() @ (y - X @ w) / n\n",
    "\n",
    "w = torch.tensor([[1.], [0]], requires_grad=True)\n",
    "y_hat = model(X, w)\n",
    "\n",
    "loss = rss(y, y_hat)\n",
    "loss.backward()\n",
    "\n",
    "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\n",
    "print('PyTorch\\'s gradient', w.grad.view(2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t0.01,\t[-1.0158551  1.9810736]\n",
      "1,\t0.01,\t[-1.0158551  1.9810736]\n",
      "2,\t0.01,\t[-1.0158551  1.9810736]\n",
      "3,\t0.01,\t[-1.0158551  1.9810736]\n",
      "4,\t0.01,\t[-1.0158551  1.9810736]\n",
      "5,\t0.01,\t[-1.0158551  1.9810736]\n",
      "6,\t0.01,\t[-1.0158551  1.9810736]\n",
      "7,\t0.01,\t[-1.0158551  1.9810736]\n",
      "8,\t0.01,\t[-1.0158551  1.9810736]\n",
      "9,\t0.01,\t[-1.0158551  1.9810736]\n",
      "10,\t0.01,\t[-1.0158551  1.9810736]\n",
      "11,\t0.01,\t[-1.0158551  1.9810736]\n",
      "12,\t0.01,\t[-1.0158551  1.9810736]\n",
      "13,\t0.01,\t[-1.0158551  1.9810736]\n",
      "14,\t0.01,\t[-1.0158551  1.9810736]\n",
      "15,\t0.01,\t[-1.0158551  1.9810736]\n",
      "16,\t0.01,\t[-1.0158551  1.9810736]\n",
      "17,\t0.01,\t[-1.0158551  1.9810736]\n",
      "18,\t0.01,\t[-1.0158551  1.9810736]\n",
      "19,\t0.01,\t[-1.0158551  1.9810736]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-1.0158551  1.9810736]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.1\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(20):\n",
    "    y_hat = model(X, w)\n",
    "    loss = rss(y, y_hat)\n",
    "    \n",
    "    loss.backward() # compute the gradient of the loss\n",
    "    \n",
    "    w.data = w.data - step_size * w.grad # do a gradient descent step\n",
    "#     w.data -= step_size * w.grad\n",
    "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), w.view(2).detach().numpy()))\n",
    "    \n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    w.grad.detach()\n",
    "    w.grad.zero_()\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', w.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor torch.Size([2, 3])\n",
      "transormed torch.Size([2, 4])\n",
      "\n",
      "We can see that the weights exist in the background\n",
      "\n",
      "W: Parameter containing:\n",
      "tensor([[-0.1580, -0.0981, -0.5399],\n",
      "        [ 0.4638,  0.0480,  0.3148],\n",
      "        [-0.1467, -0.1837,  0.5089],\n",
      "        [-0.1196,  0.5382,  0.0448]], requires_grad=True)\n",
      "b: Parameter containing:\n",
      "tensor([ 0.4099,  0.5509, -0.3729,  0.2608], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out)\n",
    "\n",
    "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\n",
    "# applys a linear transformation to the data\n",
    "transformed = linear_module(example_tensor)\n",
    "print('example_tensor', example_tensor.shape)\n",
    "print('transormed', transformed.shape)\n",
    "print()\n",
    "print('We can see that the weights exist in the background\\n')\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor tensor([-1.,  1.,  0.])\n",
      "activated tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "activation_fn = nn.ReLU() # we instantiate an instance of the ReLU module\n",
    "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
    "activated = activation_fn(example_tensor)\n",
    "print('example_tensor', example_tensor)\n",
    "print('activated', activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed tensor([[0.3223],\n",
      "        [0.3359]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_hidden = 4\n",
    "d_out = 1\n",
    "model = torch.nn.Sequential(\n",
    "                            nn.Linear(d_in, d_hidden),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(d_hidden, d_out),\n",
    "                            nn.Sigmoid()\n",
    "                           )\n",
    "\n",
    "example_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "transformed = model(example_tensor)\n",
    "print('transformed', transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4880, -0.1715,  0.3732],\n",
      "        [ 0.3882,  0.0937, -0.4099],\n",
      "        [ 0.3652, -0.3831,  0.0227],\n",
      "        [ 0.4116, -0.0352,  0.2695]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1442, -0.2094, -0.5451,  0.0690], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1441,  0.4343,  0.0841,  0.1366]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3677], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "\n",
    "for param in params:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "input = torch.tensor([[0., 0, 0]])\n",
    "target = torch.tensor([[1., 0, -1]])\n",
    "\n",
    "loss = mse_loss_fn(input, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[-0.9543]], requires_grad=True)\n",
      "model params after: Parameter containing:\n",
      "tensor([[-0.8754]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a simple model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mse_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "1,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "2,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "3,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "4,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "5,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "6,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "7,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "8,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "9,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "10,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "11,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "12,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "13,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "14,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "15,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "16,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "17,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "18,\t9.39,\t[ 0.12639225 -0.50910246]\n",
      "19,\t9.39,\t[ 0.12639225 -0.50910246]\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "linear_module = nn.Linear(d, 1, bias=False)\n",
    "optim = torch.optim.SGD(linear_module.parameters(),lr=step_size)\n",
    "step_size = 0.1\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "for i in range(20):\n",
    "    y_hat = model(X) \n",
    "    loss = mse_loss(y, y_hat)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "#     print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "    print(\"{},\\t{:.2f},\\t{}\".format(i, loss.item(), model.weight.view(2).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t8.97,\t[-0.31551167  0.08615857]\n",
      "1,\t5.06,\t[-0.5181806   0.54466945]\n",
      "2,\t2.86,\t[-0.66269034  0.89205366]\n",
      "3,\t1.62,\t[-0.76561904  1.1552937 ]\n",
      "4,\t0.92,\t[-0.83884495  1.354807  ]\n",
      "5,\t0.53,\t[-0.8908728  1.5060471]\n",
      "6,\t0.30,\t[-0.9277874  1.6207129]\n",
      "7,\t0.18,\t[-0.9539389  1.7076629]\n",
      "8,\t0.10,\t[-0.97243416  1.7736064 ]\n",
      "9,\t0.06,\t[-0.98549044  1.8236257 ]\n",
      "10,\t0.04,\t[-0.9946883  1.8615714]\n",
      "11,\t0.03,\t[-1.0011531  1.8903618]\n",
      "12,\t0.02,\t[-1.0056854  1.9122086]\n",
      "13,\t0.01,\t[-1.0088539  1.9287884]\n",
      "14,\t0.01,\t[-1.0110618  1.9413726]\n",
      "15,\t0.01,\t[-1.0125947  1.9509252]\n",
      "16,\t0.01,\t[-1.0136546  1.9581772]\n",
      "17,\t0.01,\t[-1.0143838  1.9636834]\n",
      "18,\t0.01,\t[-1.0148827  1.9678643]\n",
      "19,\t0.01,\t[-1.0152218  1.9710393]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-1.0152218  1.9710393]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "\n",
    "linear_module = nn.Linear(d, 1)\n",
    "loss_func = nn.MSELoss()\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(200):\n",
    "    rand_idx = np.random.choice(n) # take a random point from the dataset\n",
    "    x = X[rand_idx] \n",
    "    y_hat = linear_module(x)\n",
    "    loss = loss_func(y_hat, y[rand_idx]) # only compute the loss on the single point\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "input = torch.tensor([[-1., 1],[-1, 1],[1, -1]]) # raw scores correspond to the correct class\n",
    "# input = torch.tensor([[-3., 3],[-3, 3],[3, -3]]) # raw scores correspond to the correct class with higher confidence\n",
    "# input = torch.tensor([[1., -1],[1, -1],[-1, 1]]) # raw scores correspond to the incorrect class\n",
    "# input = torch.tensor([[3., -3],[3, -3],[-3, 3]]) # raw scores correspond to the incorrect class with incorrectly placed confidence\n",
    "\n",
    "target = torch.tensor([1, 1, 0])\n",
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im shape torch.Size([4, 3, 32, 32])\n",
      "convolved im shape torch.Size([4, 16, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "im_channels = 3 # if we are working with RGB images, there are 3 input channels, with black and white, 1\n",
    "out_channels = 16 # this is a hyperparameter we can tune\n",
    "kernel_size = 3 # this is another hyperparameter we can tune\n",
    "batch_size = 4\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "\n",
    "im = torch.randn(batch_size, im_channels, image_width, image_height)\n",
    "\n",
    "m = nn.Conv2d(im_channels, out_channels, kernel_size)\n",
    "convolved = m(im) # it is a module so we can call it\n",
    "\n",
    "print('im shape', im.shape)\n",
    "print('convolved im shape', convolved.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
